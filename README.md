Aqui est√° o README traduzido para o portugu√™s, adaptado para o contexto acad√™mico:

---

# **Classifica√ß√£o Automatizada de Gr√£os com Machine Learning**

Este projeto automatiza a classifica√ß√£o de gr√£os de trigo utilizando algoritmos de Machine Learning. Com base no **"Seeds Dataset"** do UCI Machine Learning Repository, exploramos t√©cnicas de pr√©-processamento de dados, treinamento de modelos de classifica√ß√£o, otimiza√ß√£o de hiperpar√¢metros e avalia√ß√£o de desempenho.

---

## **Contexto do Problema**

Em cooperativas agr√≠colas de pequeno porte, a classifica√ß√£o de gr√£os √© realizada manualmente por especialistas, o que pode ser ineficiente e propenso a erros. Este projeto automatiza esse processo, melhorando a precis√£o e efici√™ncia.

O dataset cont√©m 210 amostras de gr√£os de trigo pertencentes a tr√™s variedades:
- **Kama**
- **Rosa**
- **Canadian**

Cada amostra √© descrita por caracter√≠sticas f√≠sicas do gr√£o, permitindo a cria√ß√£o de modelos preditivos.

---

## **Detalhes do Conjunto de Dados**

O conjunto de dados possui 7 caracter√≠sticas e 1 r√≥tulo (a classe):
- **Caracter√≠sticas**:
  - √Årea do gr√£o.
  - Per√≠metro do gr√£o.
  - Compacidade:

$$
\text{Compacidade} = \frac{4 \pi \times \text{√Årea}}{\text{Per√≠metro}^2}
$$
  - Comprimento do N√∫cleo: Comprimento do eixo principal do gr√£o.
  - Largura do N√∫cleo: Comprimento do eixo secund√°rio do gr√£o.
  - Coeficiente de Assimetria: Medida da assimetria do gr√£o.
  - Comprimento do Sulco: Comprimento do sulco central do gr√£o.
- **R√≥tulo**:
  - Variedade do trigo (1 para Kama, 2 para Rosa, 3 para Canadian).

---

## **Detalhes da Implementa√ß√£o**

### **Metodologia**
Este projeto segue a metodologia **CRISP-DM**:
1. **Entendimento dos Dados**: Explora√ß√£o e visualiza√ß√£o do dataset.
2. **Prepara√ß√£o dos Dados**: Limpeza, normaliza√ß√£o e divis√£o dos dados em conjuntos de treino e teste.
3. **Modelagem**: Treinamento de m√∫ltiplos modelos de classifica√ß√£o.
4. **Avalia√ß√£o**: Compara√ß√£o do desempenho dos modelos usando m√©tricas.
5. **Resultados**: Apresenta√ß√£o dos insights e do melhor modelo.

---

### **Etapas Realizadas**

#### **1. Pr√©-processamento dos Dados**
- **Explora√ß√£o**: Visualizamos a distribui√ß√£o dos dados com histogramas, gr√°ficos de dispers√£o e KDEs.
- **Normaliza√ß√£o**: As caracter√≠sticas foram padronizadas usando:
  $$
  Z = \frac{X - \mu}{\sigma}
  $$
  onde ùúá √© a m√©dia e œÉ √© o desvio padr√£o.
- **Tratamento de Valores Ausentes**: N√£o foram encontrados valores ausentes.

#### **2. Treinamento de Modelos de Machine Learning**
Modelos utilizados:
- **K-Nearest Neighbors (KNN)**:
  - Hiperpar√¢metro: ùëò (n√∫mero de vizinhos).
  - M√©trica de dist√¢ncia: Euclidiana.
- **Support Vector Machine (SVM)**:
  - Kernels: Linear, Polinomial, RBF.
  - Regulariza√ß√£o (ùê∂): Controle de margem e erro.
  - Gamma (Œ≥): Coeficiente do kernel.
- **Random Forest**:
  - N√∫mero de √°rvores $$ n^{\text{estimators}} $$

  - Profundidade m√°xima $$ d_{\text{max}} $$

#### **3. Otimiza√ß√£o de Hiperpar√¢metros**
Utilizamos o **GridSearchCV** para otimizar os hiperpar√¢metros:
$$
\text{Acur√°cia} = \frac{\text{Previs√µes Corretas}}{\text{Total de Previs√µes}}
$$
O Grid Search avaliou todas as combina√ß√µes poss√≠veis de hiperpar√¢metros para encontrar a melhor configura√ß√£o.

#### **4. Avalia√ß√£o**
Os modelos foram avaliados utilizando:
- **Matriz de Confus√£o**:
  $$
  \begin{bmatrix}
  \text{VP} & \text{FP} \\
  \text{FN} & \text{VN}
  \end{bmatrix}
  $$
- **M√©tricas**:
  - Precis√£o: $$ \frac{\text{VP}}{\text{VP} + \text{FP}} $$
  - Recall: $$ \frac{\text{VP}}{\text{VP} + \text{FN}} $$
  - F1-Score: $$ 2 \times \frac{\text{Precis√£o} \times \text{Recall}}{\text{Precis√£o} + \text{Recall}} $$

---

### **Resultados Obtidos**
| Modelo           | Acur√°cia (%) | Melhores Hiperpar√¢metros          |
|------------------|--------------|-----------------------------------|
| KNN              | 96.7         | $$ k = 5 $$                      |
| SVM              | 97.8         | $$ C = 1, \gamma = \text{scale}, \text{kernel} = \text{rbf} $$ |
| Random Forest    | 98.5         | $$ n_{\text{estimators}} = 150, d_{\text{max}} = 30 $$ |

---

## **Instru√ß√µes de Uso**

### **1. Clone o Reposit√≥rio**
```bash
git clone <link-do-repositorio>
```

### **3. Execute o Notebook**
Abra o [notebook](./src/FASE_04_CTWP_Cap11.ipynb) em Jupyter ou Google Colab e execute as c√©lulas para reproduzir a an√°lise e o treinamento dos modelos.

---

## **Conclus√µes**

Este projeto demonstra a efic√°cia do Machine Learning na automa√ß√£o da classifica√ß√£o de gr√£os:
- **Random Forest** apresentou a maior acur√°cia, com **98.5%**.
- T√©cnicas de visualiza√ß√£o ajudaram a entender os padr√µes e rela√ß√µes entre as caracter√≠sticas.
- A otimiza√ß√£o de hiperpar√¢metros melhorou significativamente o desempenho dos modelos.
